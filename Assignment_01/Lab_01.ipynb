{"cells":[{"cell_type":"markdown","metadata":{"dc":{"key":"3"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 1. Understand the data.\n","<p>Many Myanmar people have moved to Thailand. Hence, Accurate prediction of housing prices will aid Myanmar people in making informed decisions regarding buying, selling, or renting properties, maximizing returns on investment. </p>\n","<p>Step 1: Reading the data</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"3"},"tags":["sample_code"],"trusted":true},"outputs":[],"source":["# Importing the pandas package\n","import pandas as pd\n","\n","# Reading in house_CM.csv, which is comma delimited.\n","df=pd.read_csv('condo_price_cm.csv', index_col = 0)\n","\n","# Print the number of features, number of data points\n","print(df.shape)\n","\n","# Print the name of the features of the data points\n","print(df.columns)\n","\n","# Clean the columns names\n","df.columns = [name.strip() for name in list(df.columns)]\n","print(df.columns)\n","\n","# Print the information of the dataset and check data types\n","df.info()"]},{"cell_type":"markdown","metadata":{"dc":{"key":"10"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 2. Data Preprocessing\n","<p>Data preprocessing is a critical step in machine learning that involves transforming raw data into a format that is suitable for analysis and modeling. It's an essential part of the machine learning pipeline because the quality of the data directly impacts the performance and accuracy of the models built upon it.</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"10"},"tags":["sample_code"],"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","# Select the feature 'bathroom'\n","sel_feature = 'Area'\n","\n","X=df[[sel_feature]]\n","Y=df['Prices']\n","\n","# standardize the features using the feature scaling\n","\n","X=X.apply(lambda rec:(rec-rec.mean())/rec.std(),axis=0)\n","Y=np.array((Y-Y.mean())/Y.std())\n"]},{"cell_type":"markdown","metadata":{"dc":{"key":"17"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 3. Gradient Descent Algorithm\n","<p>Gradient Descent is an optimization algorithm used to minimize the cost function in machine learning models, particularly in training processes like linear regression, logistic regression, neural networks, and more. </p>\n","<p>The goal of Gradient Descent is to find the parameters (coefficients) of the model that minimize the cost function, making the model perform better at predicting the target variable.</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"17"},"tags":["sample_code"],"trusted":true},"outputs":[],"source":["import random\n","\n","##This function initializes the parameters (coefficients) of the model.\n","def initialize(dim):\n","    b=random.random()\n","    a=np.random.rand(dim)\n","    return b,a\n","\n","##This function computes the predicted values (Y_hat) based on the input features (X) and the model parameters (b and a).\n","def predict_Y(b,a,X):\n","    return b + np.dot(X,a)\n","\n","##This function computes the cost between the actual target values (Y) and the predicted values (Y_hat).\n","def get_cost(Y,Y_hat):\n","    Y_resd=Y-Y_hat\n","    return np.sum(np.dot(Y_resd.T,Y_resd))/len(Y)\n","\n","##This function updates the parameters (b_0 and theta_o) using gradient descent based on the gradients and the learning rate.\n","def update_theta(x,y,y_hat,b_0,theta_o,learning_rate):\n","    db=(np.sum(y_hat-y)*2)/len(y)\n","    dw=(np.dot((y_hat-y),x)*2)/len(y)\n","    b_1=b_0-learning_rate*db\n","    theta_1=theta_o-learning_rate*dw\n","    return b_1,theta_1\n","\n","#This function performs the gradient descent optimization process for linear regression.\n","def run_gradient_descent(X,Y,alpha,num_iterations):\n","    tolerance = 1e-06\n","    b,theta=initialize(X.shape[1])\n","    \n","    gd_iterations_df=pd.DataFrame(columns=['iteration','value_b', 'value_weight', 'cost'])\n","    result_idx=0\n","    prev_cost =0 \n","    \n","    for iter_num in range(num_iterations):\n","        Y_hat=predict_Y(b,theta,X)\n","        this_cost=get_cost(Y,Y_hat)\n","        prev_b=b\n","        prev_theta=theta\n","        b,theta=update_theta(X,Y,Y_hat,prev_b,prev_theta,alpha)\n","        gd_iterations_df.loc[result_idx]=[iter_num,b, theta[0], this_cost]\n","        result_idx=result_idx+1   \n","        if (np.abs(this_cost  - prev_cost )<= tolerance):\n","            break\n","        prev_cost = this_cost\n","    return gd_iterations_df,b,theta\n","        \n","gd_iterations_df,b,theta=run_gradient_descent(X,Y,alpha=0.01,num_iterations=400)\n","\n","\n","# import matplotlib for visualization\n","import matplotlib.pyplot as plt\n","\n","# plot the results\n","\n","plt.plot(gd_iterations_df['iteration'], gd_iterations_df['cost'], \"*\")"]},{"cell_type":"markdown","metadata":{"dc":{"key":"24"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 4. Check the parameters\n","<p>Retrieves the value of the parameters corresponding to the minimum cost.</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"dc":{"key":"24"},"tags":["sample_code"],"trusted":true},"outputs":[],"source":["idx = gd_iterations_df['cost'].argmin()\n","best_parameters = gd_iterations_df.loc[idx, ['value_b', 'value_weight']]\n","\n","# print the values of the parameters \n","print('Best parameters found at index', idx)\n","print(best_parameters)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"31"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 5. Perform the predictions\n","<p>Now that we have identified the best parameters corresponding to the minimum cost. Make predictions using the best parameters obtained from the Gradient Descent optimization. </p>"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"dc":{"key":"31"},"tags":["sample_code"],"trusted":true},"outputs":[],"source":["y_ini = gd_iterations_df.loc[0, 'value_b'] + gd_iterations_df.loc[0, 'value_weight']*X\n","y_hat = gd_iterations_df.loc[idx, 'value_b'] + gd_iterations_df.loc[idx, 'value_weight']*X"]},{"cell_type":"markdown","metadata":{},"source":["## 6. Visualize the results.\n","<p>Draw a scatter plot to visualize the relationship between the selected program variable (sel_feature) and the sales data, along with the predicted sales based on initial and best parameters obtained from a gradient descent optimization process.</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"dc":{"key":"38"},"tags":["sample_code"],"trusted":true},"outputs":[],"source":["# import matplotlib for visualization\n","import matplotlib.pyplot as plt\n","\n","# plot the actual data points\n","plt.plot(X, Y, '*')\n","\n","plt.plot(X,  y_ini, 'k', X, y_hat, 'r')\n","plt.legend(['actual prices', 'predicted prices with initial parameters',\n","            'predicted prices with best parameters'])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## 7. Submit for the grade.\n","<p>Change the below cell code for the final submission</p>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Edit the below code to change to your name.\n","name = \"student name\"\n","print(\"Submitted by\", name)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":2}
